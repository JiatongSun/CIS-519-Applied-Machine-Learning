{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DnokyRPqBJ7n"
   },
   "source": [
    "# CIS 419/519 Homework 1\n",
    "\n",
    "Name: Jiatong Sun\n",
    "\n",
    "Pennkey: jtsun\n",
    "\n",
    "PennID: 53378755"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JXCMO-KSHept"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "random.seed(42)  # don't change this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Asyzto_DKfBQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8140, 1812)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>RIDSTATR</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>RIDAGEMN</th>\n",
       "      <th>RIDRETH1</th>\n",
       "      <th>RIDRETH3</th>\n",
       "      <th>RIDEXMON</th>\n",
       "      <th>RIDEXAGM</th>\n",
       "      <th>...</th>\n",
       "      <th>WHD080L</th>\n",
       "      <th>WHD110</th>\n",
       "      <th>WHD120</th>\n",
       "      <th>WHD130</th>\n",
       "      <th>WHD140</th>\n",
       "      <th>WHQ150</th>\n",
       "      <th>WHQ030M</th>\n",
       "      <th>WHQ500</th>\n",
       "      <th>WHQ520</th>\n",
       "      <th>DIABETIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76195</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76958</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80248</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80213</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76753</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1812 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SEQN  SDDSRVYR  RIDSTATR  RIAGENDR  RIDAGEYR  RIDAGEMN  RIDRETH1  \\\n",
       "0  76195         8         2         1        18       NaN         5   \n",
       "1  76958         8         2         2        57       NaN         2   \n",
       "2  80248         8         2         2        29       NaN         2   \n",
       "3  80213         8         2         2         0       5.0         1   \n",
       "4  76753         8         2         1        61       NaN         3   \n",
       "\n",
       "   RIDRETH3  RIDEXMON  RIDEXAGM  ...  WHD080L  WHD110  WHD120  WHD130  WHD140  \\\n",
       "0         7       1.0     217.0  ...      NaN     NaN     NaN     NaN   138.0   \n",
       "1         2       1.0       NaN  ...      NaN   135.0   115.0    67.0   150.0   \n",
       "2         2       2.0       NaN  ...      NaN     NaN   125.0     NaN   160.0   \n",
       "3         1       2.0       6.0  ...      NaN     NaN     NaN     NaN     NaN   \n",
       "4         3       2.0       NaN  ...      NaN   160.0   160.0    69.0   180.0   \n",
       "\n",
       "   WHQ150  WHQ030M  WHQ500  WHQ520  DIABETIC  \n",
       "0    18.0      NaN     NaN     NaN         0  \n",
       "1    45.0      NaN     NaN     NaN         0  \n",
       "2    28.0      NaN     NaN     NaN         0  \n",
       "3     NaN      NaN     NaN     NaN         0  \n",
       "4    30.0      NaN     NaN     NaN         0  \n",
       "\n",
       "[5 rows x 1812 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all data tables\n",
    "baseDir = './'## TODO: insert path to data file\n",
    "df = pd.read_csv(baseDir+'NHANES-diabetes-hw-train.csv')\n",
    "\n",
    "# Output debugging info\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UvNtFvGqKfDx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of instances with missing features:\n",
      "SEQN        0.000000\n",
      "SDDSRVYR    0.000000\n",
      "RIDSTATR    0.000000\n",
      "RIAGENDR    0.000000\n",
      "RIDAGEYR    0.000000\n",
      "              ...   \n",
      "WHQ150      0.407371\n",
      "WHQ030M     0.853563\n",
      "WHQ500      0.853563\n",
      "WHQ520      0.853563\n",
      "DIABETIC    0.000000\n",
      "Length: 1812, dtype: float64\n",
      "\n",
      "Class information:\n",
      "0    7447\n",
      "1     693\n",
      "Name: DIABETIC, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print information about the dataset\n",
    "print('Percentage of instances with missing features:')\n",
    "print(df.isnull().sum(axis=0)/df.shape[0])\n",
    "print()\n",
    "print('Class information:')\n",
    "print(df['DIABETIC'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vhfk9CQoXfae"
   },
   "source": [
    "## **Preprocessing**\n",
    "\n",
    "The first key step in any data modeling task is cleaning your dataset. Explore your dataset and figure out what sort of preprocessing is required. Good preprocessing can make or break your final model. So choose wisely.\n",
    "\n",
    "Some of the preprocessing steps that you can consider are :\n",
    "\n",
    "\n",
    "*   One-hot encoding of variables\n",
    "*   Missing value imputation\n",
    "*   Removing outliers\n",
    "*   Converting binary features into 0-1 representation\n",
    "\n",
    "\n",
    "Feel free to reuse code you've already written in HW 0.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Insert your preprocessing code here\n",
    "\n",
    "# The complete preprocessing function\n",
    "def preprocessing(inputDf,missing_thresh):\n",
    "    outputDf = inputDf.copy()\n",
    "    # drop feature that misses too many data\n",
    "    outputDf = dropMissingColumn(outputDf,missing_thresh)\n",
    "    # replenish missing data\n",
    "    outputDf = fillMissingColumn(outputDf)\n",
    "    return outputDf\n",
    "\n",
    "# drop the column whose missing ratio is too high\n",
    "def dropMissingColumn(inputDf,missing_thresh):\n",
    "    outputDf = inputDf.copy()\n",
    "    missDf = getMissingRatio(outputDf)\n",
    "    missIdx = missDf['MissingPercent'] >= missing_thresh\n",
    "    missFeat = missDf.loc[missIdx,'Feature']\n",
    "    outputDf = outputDf.drop(missFeat,axis=1)\n",
    "    return outputDf\n",
    "\n",
    "# fill the NaN\n",
    "def fillMissingColumn(inputDf):\n",
    "    outputDf = inputDf.copy()\n",
    "    # replenish numerical with mean\n",
    "    numerical_col = (outputDf.iloc[:,].dtypes!='O').values\n",
    "    numericalDf = outputDf.iloc[:,numerical_col]\n",
    "    numericalDf = numericalDf.fillna(numericalDf.mean())\n",
    "    # replenish category with mode\n",
    "    category_col = (outputDf.iloc[:,].dtypes=='O').values\n",
    "    categoryDf = outputDf.iloc[:,category_col]\n",
    "    categoryDf = categoryDf.fillna(categoryDf.mode().iloc[0])\n",
    "    if not categoryDf.empty:\n",
    "        categoryDf = pd.get_dummies(categoryDf)\n",
    "    # combine two dataframes\n",
    "    outputDf = pd.concat([numericalDf,categoryDf],axis=1)\n",
    "    return outputDf\n",
    "\n",
    "# calculate the missing ratio of each column\n",
    "def getMissingRatio(inputDf):\n",
    "    outSeries = inputDf.isna().mean()                 # calculate missing ratios\n",
    "    outDf = pd.DataFrame({'Feature':outSeries.index,\\\n",
    "                          'MissingPercent':outSeries.values})\n",
    "    return outDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Fupod-VnNzu"
   },
   "outputs": [],
   "source": [
    "# Generate feature set from preprocessed data set\n",
    "\n",
    "# Extract features w.r.t. correlation\n",
    "def extractFeatures(X,y,num_feature):\n",
    "    completeDf = pd.concat([X,y], axis = 1)\n",
    "    corrDf = completeDf.corr().iloc[-1,:-1]\n",
    "    corrDf = abs(corrDf).sort_values(ascending=False)\n",
    "    feature_index = corrDf.index[:num_feature]\n",
    "    X_out = X[feature_index]\n",
    "    return X_out, feature_index\n",
    "\n",
    "# Select features randomly\n",
    "def randomFeatures(X,num_feature,random_seed):\n",
    "    random.seed(random_seed)\n",
    "    idx = np.arange(0,X.shape[1])\n",
    "    random.shuffle(idx)\n",
    "    X_out = X.iloc[:,idx[:10]]\n",
    "    feature_index = X_out.columns\n",
    "    return X_out, feature_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetic Ratio (Label): 0.09\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "X = df.drop(['SEQN','DIQ010','DIABETIC'],axis=1)\n",
    "y = df['DIABETIC']\n",
    "\n",
    "print(f'Diabetic Ratio (Label): {y.values.sum()/len(y):.2f}\\n')\n",
    "\n",
    "X = preprocessing(X,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate three different sub data set\n",
    "\n",
    "feat_list = list()\n",
    "# feature set 1: by corr\n",
    "X1, feature_1 = extractFeatures(X,y,13)\n",
    "feat_list.append(feature_1)\n",
    "\n",
    "# feature set 2: by random\n",
    "X2, feature_2 = randomFeatures(X,13,random_seed)\n",
    "feat_list.append(feature_2)\n",
    "\n",
    "# feature set 3: by given example\n",
    "feature_3 = ['RIDAGEYR','BMXWAIST','BMXHT','LBXTC','BMXLEG','BMXWT','BMXBMI',\n",
    "             'RIDRETH1','BPQ020','ALQ120Q','DMDEDUC2','RIAGENDR','INDFMPIR']\n",
    "X3 = X[feature_3]\n",
    "feat_list.append(feature_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F_HqomJOap0j"
   },
   "source": [
    "## **Modeling**\n",
    "\n",
    "In this section, you are tasked with building a Decision Tree classifier to predict whether or not a patient has diabetes. The overall goal of this exercise is to investigate the dataset and develop features that would improve your model performance.\n",
    "\n",
    "To help with this process, we have provided the structure for two helper functions. These functions will help in tuning your model as well as validating your model's performance.\n",
    "\n",
    "Complete these two functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rsr6KV5wKfJB"
   },
   "outputs": [],
   "source": [
    "def cross_validated_accuracy(DecisionTreeClassifier, X, y, num_trials, num_folds, random_seed):\n",
    "    random.seed(random_seed)\n",
    "    \"\"\"\n",
    "     Args:\n",
    "          DecisionTreeClassifier: An Sklearn DecisionTreeClassifier (e.g., created by \"tree.DecisionTreeClassifier(criterion='entropy')\")\n",
    "          X: Input features\n",
    "          y: Labels\n",
    "          num_trials: Number of trials to run of cross validation\n",
    "          num_folds: Number of folds (the \"k\" in \"k-folds\")\n",
    "          random_seed: Seed for uniform execution (Do not change this) \n",
    "\n",
    "      Returns:\n",
    "          cvScore: The mean accuracy of the cross-validation experiment\n",
    "\n",
    "      Notes:\n",
    "          1. You may NOT use the cross-validation functions provided by Sklearn\n",
    "    \"\"\"\n",
    "\n",
    "    ## TODO ##\n",
    "    num_correct = 0\n",
    "    num_test = 0\n",
    "    accuracy_list = list()\n",
    "    for i in range(num_trials):\n",
    "        idx = np.arange(0,X.shape[0])\n",
    "        random.shuffle(idx)\n",
    "        X_shuf = X.set_index(idx).sort_index()\n",
    "        y_shuf = y.copy()\n",
    "        y_shuf.index = idx\n",
    "        y_shuf = y_shuf.sort_index()\n",
    "        for j in range(num_folds):\n",
    "            X_split = np.array_split(X_shuf, num_folds)\n",
    "            y_split = np.array_split(y_shuf, num_folds)\n",
    "            X_test = X_split.pop(j)\n",
    "            y_test = y_split.pop(j)\n",
    "            X_train = pd.concat(X_split)\n",
    "            y_train = pd.concat(y_split)\n",
    "            model = DecisionTreeClassifier.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            num_correct += (y_pred == y_test).sum()\n",
    "            num_test += len(y_test)\n",
    "            accuracy_list.append((y_pred == y_test).sum()/len(y_test))\n",
    "    cvScore = num_correct / num_test\n",
    "    x_bar = np.mean(accuracy_list)\n",
    "    ssd = np.std(accuracy_list)\n",
    "    num_obs = len(accuracy_list)\n",
    "    t_param = 2.626   # look into the t-table\n",
    "    low_bound = round(x_bar - t_param * ssd / np.sqrt(num_obs),3)\n",
    "    upper_bound = round(x_bar + t_param * ssd / np.sqrt(num_obs),3)\n",
    "    interval = (low_bound, upper_bound)\n",
    "    print(f'Confidence Interval: {interval}')\n",
    "    \n",
    "    return cvScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNISvwuvKvjP"
   },
   "outputs": [],
   "source": [
    "def automatic_dt_pruning(DecisionTreeClassifier, X, y, num_trials, num_folds, random_seed):\n",
    "    random.seed(random_seed)\n",
    "    \"\"\"\n",
    "    Returns the pruning parameter (i.e., ccp_alpha) with the highest cross-validated accuracy\n",
    "\n",
    "    Args:\n",
    "          DecisionTreeClassifier  : An Sklearn DecisionTreeClassifier (e.g., created by \"tree.DecisionTreeClassifier(criterion='entropy')\")      \n",
    "          X (Pandas.DataFrame)    : Input Features\n",
    "          y (Pandas.Series)       : Labels\n",
    "          num_trials              : Number of trials to run of cross validation\n",
    "          num_folds               : Number of folds for cross validation (The \"k\" in \"k-folds\") \n",
    "          random_seed             : Seed for uniform execution (Do not change this)\n",
    "\n",
    "\n",
    "    Returns:\n",
    "          ccp_alpha : Tuned pruning paramter with highest cross-validated accuracy\n",
    "\n",
    "    Notes:\n",
    "        1. Don't change any other Decision Tree Classifier parameters other than ccp_alpha\n",
    "        2. Use the cross_validated_accuracy function you implemented to find the cross-validated accuracy\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    ## TODO ##\n",
    "    ccp_idx = np.linspace(0,1,101)\n",
    "    last_accuracy = 0\n",
    "    for cur_ccp in ccp_idx:\n",
    "        DecisionTreeClassifier.ccp_alpha = cur_ccp\n",
    "        cur_accuracy = cross_validated_accuracy(DecisionTreeClassifier,\n",
    "                            X, y, num_trials, num_folds, random_seed)\n",
    "        print(f'ccp_alpha = {cur_ccp:.2f}: {round(cur_accuracy,3)}\\n')\n",
    "        if last_accuracy - cur_accuracy > 0.01:\n",
    "            return (cur_ccp - 0.01)\n",
    "        else:\n",
    "            last_accuracy = cur_accuracy\n",
    "    ccp_alpha = cur_ccp\n",
    "    \n",
    "    return ccp_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-LfgMo78b6SQ"
   },
   "source": [
    "## **Tuning and Testing**\n",
    "\n",
    "With the helper functions and your processed dataset, build a Decision Tree classifier to classify Diabetic patients and tune it to maximize model performance.\n",
    "\n",
    "Once you are done with your modeling process, test your model on the test dataset and output your predictions in a file titled \"cis519_hw1_predictions.csv\", with one row per prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set learning parameters\n",
    "num_trials = 10\n",
    "num_folds = 10\n",
    "T = tree.DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSVrMo_RcYti"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval: (0.927, 0.931)\n",
      "feature 1 accuracy: 0.929\n",
      "Confidence Interval: (0.862, 0.868)\n",
      "feature 2 accuracy: 0.865\n",
      "Confidence Interval: (0.875, 0.881)\n",
      "feature 3 accuracy: 0.878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## TODO ##\n",
    "\n",
    "# Cross-Validation on three data set\n",
    "# Feature set 1: by corr\n",
    "cvScore_1 = cross_validated_accuracy(T, \n",
    "               X1, y, num_trials, num_folds, random_seed)\n",
    "print(f'feature 1 accuracy: {cvScore_1:.3f}')\n",
    "\n",
    "# Feature set 2: by random\n",
    "cvScore_2 = cross_validated_accuracy(T, \n",
    "               X2, y, num_trials, num_folds, random_seed)\n",
    "print(f'feature 2 accuracy: {cvScore_2:.3f}')\n",
    "\n",
    "# Feature set 3: by given example\n",
    "cvScore_3 = cross_validated_accuracy(T, \n",
    "               X3, y, num_trials, num_folds, random_seed)\n",
    "print(f'feature 3 accuracy: {cvScore_3:.3f}\\n')\n",
    "\n",
    "# Compare the accuracies and choose the best feature set\n",
    "best_index = np.argmax([cvScore_1,cvScore_2,cvScore_3])\n",
    "best_accuracy = max([cvScore_1,cvScore_2,cvScore_3])\n",
    "best_feat = feat_list[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval: (0.926, 0.931)\n",
      "ccp_alpha = 0.00: 0.929\n",
      "\n",
      "Confidence Interval: (0.94, 0.944)\n",
      "ccp_alpha = 0.01: 0.942\n",
      "\n",
      "Confidence Interval: (0.934, 0.938)\n",
      "ccp_alpha = 0.02: 0.936\n",
      "\n",
      "Confidence Interval: (0.934, 0.938)\n",
      "ccp_alpha = 0.03: 0.936\n",
      "\n",
      "Confidence Interval: (0.934, 0.938)\n",
      "ccp_alpha = 0.04: 0.936\n",
      "\n",
      "Confidence Interval: (0.934, 0.938)\n",
      "ccp_alpha = 0.05: 0.936\n",
      "\n",
      "Confidence Interval: (0.934, 0.938)\n",
      "ccp_alpha = 0.06: 0.936\n",
      "\n",
      "Confidence Interval: (0.934, 0.938)\n",
      "ccp_alpha = 0.07: 0.936\n",
      "\n",
      "Confidence Interval: (0.934, 0.938)\n",
      "ccp_alpha = 0.08: 0.936\n",
      "\n",
      "Confidence Interval: (0.934, 0.938)\n",
      "ccp_alpha = 0.09: 0.936\n",
      "\n",
      "Confidence Interval: (0.934, 0.938)\n",
      "ccp_alpha = 0.10: 0.936\n",
      "\n",
      "Confidence Interval: (0.934, 0.938)\n",
      "ccp_alpha = 0.11: 0.936\n",
      "\n",
      "Confidence Interval: (0.934, 0.938)\n",
      "ccp_alpha = 0.12: 0.936\n",
      "\n",
      "Confidence Interval: (0.934, 0.938)\n",
      "ccp_alpha = 0.13: 0.936\n",
      "\n",
      "Confidence Interval: (0.933, 0.938)\n",
      "ccp_alpha = 0.14: 0.935\n",
      "\n",
      "Confidence Interval: (0.913, 0.919)\n",
      "ccp_alpha = 0.15: 0.916\n",
      "\n",
      "\n",
      "best feature set: feature_1\n",
      "best accuracy: 0.929\n",
      "best feature:\n",
      " ['LBDSGLSI' 'LBXSGL' 'DIQ050' 'RIDAGEYR' 'BMXWAIST' 'BMDAVSAD' 'BMXSAD2'\n",
      " 'BMXSAD1' 'DMDHHSZE' 'HUQ010' 'DMDHRAGE' 'BPQ090D' 'BMXBMI']\n",
      "\n",
      "best ccp_alpha: 0.14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prune the tree\n",
    "X_train = X[best_feat]\n",
    "best_ccp = automatic_dt_pruning(T, \n",
    "                X_train, y, num_trials, num_folds, random_seed)\n",
    "# Show result\n",
    "print(f'\\nbest feature set: feature_{best_index+1}')\n",
    "print(f'best accuracy: {round(best_accuracy,3)}')\n",
    "print(f'best feature:\\n {best_feat.values}\\n')\n",
    "print(f'best ccp_alpha: {round(best_ccp,2)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetic Ratio (Unabel): 0.07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on unlabelled data set\n",
    "X_unlabel = pd.read_csv('hw1-NHANES-diabetes-test-unlabeled.csv')\n",
    "X_unlabel = preprocessing(X_unlabel,1)\n",
    "X_unlabel = X_unlabel[best_feat]\n",
    "T.ccp_alpha = best_ccp\n",
    "T = T.fit(X_train, y)\n",
    "y_pred = T.predict(X_unlabel)\n",
    "predDf = pd.Series(y_pred).rename('DIABETIC')\n",
    "predDf.to_csv('cis519_hw1_predictions.csv',header = False,index = False)\n",
    "print(f'Diabetic Ratio (Unabel): {y_pred.sum()/len(y_pred):.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1_Skeleton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
